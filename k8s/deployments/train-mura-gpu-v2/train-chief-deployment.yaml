apiVersion: apps/v1
kind: Deployment
metadata:
  name: chief
  namespace: medtune
spec:
  replicas: 1
  selector:
    matchLabels:
      name: chief
  template:
    metadata:
      name: chief
      labels:
        name: chief
    spec:
      nodeSelector:
        cloud.google.com/gke-accelerator: nvidia-tesla-k80
      containers:
      - name: chief
        image: medtune/k8s-tf:train-mura-gpu-v2
        args: ["/etc/train/config.yaml", "/etc/train/config.yaml"]
        env:
          - name: TF_CONFIG
            valueFrom:
              configMapKeyRef:
                name: mura
                key: node.chief
        ports:
          - containerPort: 2222
        resources:
          requests:
            cpu: 3000m
            memory: 10000Mi
            nvidia.com/gpu: 1
          limits:
            cpu: 5000m
            memory: 15000Mi
            nvidia.com/gpu: 1
        volumeMounts:
          - mountPath: /nfs
            name: nfs-volume

          - mountPath: /etc/train
            name: train-config

      volumes:
        - name: nfs-volume
          persistentVolumeClaim:
            claimName: train-pvc

        - name: train-config
          configMap:
            name: mura-config

      restartPolicy: Always